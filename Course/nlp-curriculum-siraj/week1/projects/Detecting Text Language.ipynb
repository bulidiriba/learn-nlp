{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Text Language by Counting Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tutorial is based on http://blog.alejandronolla.com/2013/05/15/detecting-text-language-with-python-and-nltk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are Stop Words ?\n",
    "\n",
    "Stop words are words which are filtered out before processing because \n",
    "\n",
    "1 they are mostly grammatical as opposed to semantic in nature e.g search engine removes words like \"want\"\n",
    "\n",
    "\n",
    "But removing stop words in machine translation leads to wrong answers. because if we remove them they the machine\n",
    "can returns un expected results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    **How can We Detect the Language that a specified Text belongs using Stop Words?**\n",
    "\n",
    "this is pretty easy\n",
    "\n",
    "first tokenize the given text then identify stopwords in this text using the stop words with NLTK library.\n",
    "then find this identified stop words in stop words of all languages in the provided NLTK library and count its frequency and store it as language:numbers then the specified text is belongs to the language with high number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Yo man, it's time for you to shut yo' mouth! I ain't even messin' dawg.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jeder hat das Recht auf Bildung. Die Bildung ist unentgeltlich, zum mindesten der Grundschulunterricht und die grundlegende Bildung. Der Grundschulunterricht ist obligatorisch. Fach- und Berufsschulunterricht müssen allgemein verfügbar gemacht werden, und der Hochschulunterricht muß allen gleichermaßen entsprechend ihren Fähigkeiten offenstehen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    from nltk.tokenize import wordpunct_tokenize # word punctuation tokenizer is Regular Expression based Tokenizer, \n",
    "    # which splits text on white space and punctuation(except for underscore)\n",
    "except ImportError:\n",
    "    print('[!] You need to install nltk')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeder',\n",
       " 'hat',\n",
       " 'das',\n",
       " 'Recht',\n",
       " 'auf',\n",
       " 'Bildung',\n",
       " '.',\n",
       " 'Die',\n",
       " 'Bildung',\n",
       " 'ist',\n",
       " 'unentgeltlich',\n",
       " ',',\n",
       " 'zum',\n",
       " 'mindesten',\n",
       " 'der',\n",
       " 'Grundschulunterricht',\n",
       " 'und',\n",
       " 'die',\n",
       " 'grundlegende',\n",
       " 'Bildung',\n",
       " '.',\n",
       " 'Der',\n",
       " 'Grundschulunterricht',\n",
       " 'ist',\n",
       " 'obligatorisch',\n",
       " '.',\n",
       " 'Fach',\n",
       " '-',\n",
       " 'und',\n",
       " 'Berufsschulunterricht',\n",
       " 'müssen',\n",
       " 'allgemein',\n",
       " 'verfügbar',\n",
       " 'gemacht',\n",
       " 'werden',\n",
       " ',',\n",
       " 'und',\n",
       " 'der',\n",
       " 'Hochschulunterricht',\n",
       " 'muß',\n",
       " 'allen',\n",
       " 'gleichermaßen',\n",
       " 'entsprechend',\n",
       " 'ihren',\n",
       " 'Fähigkeiten',\n",
       " 'offenstehen']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokens = wordpunct_tokenize(text)\n",
    "test_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also THere are other Tokenizers like\n",
    "\n",
    "1. RegexpTokenizer -- where you can enter your own regexp\n",
    "\n",
    "2. WhitespaceTokenizer -- similar to Python's string.split()\n",
    "\n",
    "3. BlanklineTokenizer -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploring NLTK'S stop words corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK comes with a corpus of stop words in various languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.readme().replace('\\n', ' ') # since this is raw text, we need to replace \\n's with spaces for it to be readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"αλλα\\nαν\\nαντι\\nαπο\\nαυτα\\nαυτεσ\\nαυτη\\nαυτο\\nαυτοι\\nαυτοσ\\nαυτουσ\\nαυτων\\nαἱ\\nαἳ\\nαἵ\\nαὐτόσ\\nαὐτὸς\\nαὖ\\nγάρ\\nγα\\nγα^\\nγε\\nγια\\nγοῦν\\nγὰρ\\nδ'\\nδέ\\nδή\\nδαί\\nδαίσ\\nδαὶ\\nδαὶς\\nδε\\nδεν\\nδι'\\nδιά\\nδιὰ\\nδὲ\\nδὴ\\nδ’\\nεαν\\nειμαι\\nειμαστε\\nειναι\\nεισαι\\nειστε\\nεκεινα\\nεκεινεσ\\nεκεινη\\nεκεινο\\nεκεινοι\\nεκεινοσ\\nεκεινουσ\\nεκεινων\\nενω\\nεπ\\nεπι\\nεἰ\\nεἰμί\\nεἰμὶ\\nεἰς\\nεἰσ\\nεἴ\\nεἴμι\\nεἴτε\\nη\\nθα\\nισωσ\\nκ\\nκαί\\nκαίτοι\\nκαθ\\nκαι\\nκατ\\nκατά\\nκατα\\nκατὰ\\nκαὶ\\nκι\\nκἀν\\nκἂν\\nμέν\\nμή\\nμήτε\\nμα\\nμε\\nμεθ\\nμετ\\nμετά\\nμετα\\nμετὰ\\nμη\\nμην\\nμἐν\\nμὲν\\nμὴ\\nμὴν\\nνα\\nο\\nοι\\nομωσ\\nοπωσ\\nοσο\\nοτι\\nοἱ\\nοἳ\\nοἷς\\nοὐ\\nοὐδ\\nοὐδέ\\nοὐδείσ\\nοὐδεὶς\\nοὐδὲ\\nοὐδὲν\\nοὐκ\\nοὐχ\\nοὐχὶ\\nοὓς\\nοὔτε\\nοὕτω\\nοὕτως\\nοὕτωσ\\nοὖν\\nοὗ\\nοὗτος\\nοὗτοσ\\nπαρ\\nπαρά\\nπαρα\\nπαρὰ\\nπερί\\nπερὶ\\nποια\\nποιεσ\\nποιο\\nποιοι\\nποιοσ\\nποιουσ\\nποιων\\nποτε\\nπου\\nποῦ\\nπρο\\nπροσ\\nπρόσ\\nπρὸ\\nπρὸς\\nπως\\nπωσ\\nσε\\nστη\\nστην\\nστο\\nστον\\nσόσ\\nσύ\\nσύν\\nσὸς\\nσὺ\\nσὺν\\nτά\\nτήν\\nτί\\nτίς\\nτίσ\\nτα\\nταῖς\\nτε\\nτην\\nτησ\\nτι\\nτινα\\nτις\\nτισ\\nτο\\nτοί\\nτοι\\nτοιοῦτος\\nτοιοῦτοσ\\nτον\\nτοτε\\nτου\\nτούσ\\nτοὺς\\nτοῖς\\nτοῦ\\nτων\\nτό\\nτόν\\nτότε\\nτὰ\\nτὰς\\nτὴν\\nτὸ\\nτὸν\\nτῆς\\nτῆσ\\nτῇ\\nτῶν\\nτῷ\\nωσ\\nἀλλ'\\nἀλλά\\nἀλλὰ\\nἀλλ’\\nἀπ\\nἀπό\\nἀπὸ\\nἀφ\\nἂν\\nἃ\\nἄλλος\\nἄλλοσ\\nἄν\\nἄρα\\nἅμα\\nἐάν\\nἐγώ\\nἐγὼ\\nἐκ\\nἐμόσ\\nἐμὸς\\nἐν\\nἐξ\\nἐπί\\nἐπεὶ\\nἐπὶ\\nἐστι\\nἐφ\\nἐὰν\\nἑαυτοῦ\\nἔτι\\nἡ\\nἢ\\nἣ\\nἤ\\nἥ\\nἧς\\nἵνα\\nὁ\\nὃ\\nὃν\\nὃς\\nὅ\\nὅδε\\nὅθεν\\nὅπερ\\nὅς\\nὅσ\\nὅστις\\nὅστισ\\nὅτε\\nὅτι\\nὑμόσ\\nὑπ\\nὑπέρ\\nὑπό\\nὑπὲρ\\nὑπὸ\\nὡς\\nὡσ\\nὥς\\nὥστε\\nὦ\\nᾧ\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['αλλα',\n",
       " 'αν',\n",
       " 'αντι',\n",
       " 'απο',\n",
       " 'αυτα',\n",
       " 'αυτεσ',\n",
       " 'αυτη',\n",
       " 'αυτο',\n",
       " 'αυτοι',\n",
       " 'αυτοσ',\n",
       " 'αυτουσ',\n",
       " 'αυτων',\n",
       " 'αἱ',\n",
       " 'αἳ',\n",
       " 'αἵ',\n",
       " 'αὐτόσ',\n",
       " 'αὐτὸς',\n",
       " 'αὖ',\n",
       " 'γάρ',\n",
       " 'γα',\n",
       " 'γα^',\n",
       " 'γε',\n",
       " 'για',\n",
       " 'γοῦν',\n",
       " 'γὰρ',\n",
       " \"δ'\",\n",
       " 'δέ',\n",
       " 'δή',\n",
       " 'δαί',\n",
       " 'δαίσ',\n",
       " 'δαὶ',\n",
       " 'δαὶς',\n",
       " 'δε',\n",
       " 'δεν',\n",
       " \"δι'\",\n",
       " 'διά',\n",
       " 'διὰ',\n",
       " 'δὲ',\n",
       " 'δὴ',\n",
       " 'δ’',\n",
       " 'εαν',\n",
       " 'ειμαι',\n",
       " 'ειμαστε',\n",
       " 'ειναι',\n",
       " 'εισαι',\n",
       " 'ειστε',\n",
       " 'εκεινα',\n",
       " 'εκεινεσ',\n",
       " 'εκεινη',\n",
       " 'εκεινο',\n",
       " 'εκεινοι',\n",
       " 'εκεινοσ',\n",
       " 'εκεινουσ',\n",
       " 'εκεινων',\n",
       " 'ενω',\n",
       " 'επ',\n",
       " 'επι',\n",
       " 'εἰ',\n",
       " 'εἰμί',\n",
       " 'εἰμὶ',\n",
       " 'εἰς',\n",
       " 'εἰσ',\n",
       " 'εἴ',\n",
       " 'εἴμι',\n",
       " 'εἴτε',\n",
       " 'η',\n",
       " 'θα',\n",
       " 'ισωσ',\n",
       " 'κ',\n",
       " 'καί',\n",
       " 'καίτοι',\n",
       " 'καθ',\n",
       " 'και',\n",
       " 'κατ',\n",
       " 'κατά',\n",
       " 'κατα',\n",
       " 'κατὰ',\n",
       " 'καὶ',\n",
       " 'κι',\n",
       " 'κἀν',\n",
       " 'κἂν',\n",
       " 'μέν',\n",
       " 'μή',\n",
       " 'μήτε',\n",
       " 'μα',\n",
       " 'με',\n",
       " 'μεθ',\n",
       " 'μετ',\n",
       " 'μετά',\n",
       " 'μετα',\n",
       " 'μετὰ',\n",
       " 'μη',\n",
       " 'μην',\n",
       " 'μἐν',\n",
       " 'μὲν',\n",
       " 'μὴ',\n",
       " 'μὴν',\n",
       " 'να',\n",
       " 'ο',\n",
       " 'οι',\n",
       " 'ομωσ',\n",
       " 'οπωσ',\n",
       " 'οσο',\n",
       " 'οτι',\n",
       " 'οἱ',\n",
       " 'οἳ',\n",
       " 'οἷς',\n",
       " 'οὐ',\n",
       " 'οὐδ',\n",
       " 'οὐδέ',\n",
       " 'οὐδείσ',\n",
       " 'οὐδεὶς',\n",
       " 'οὐδὲ',\n",
       " 'οὐδὲν',\n",
       " 'οὐκ',\n",
       " 'οὐχ',\n",
       " 'οὐχὶ',\n",
       " 'οὓς',\n",
       " 'οὔτε',\n",
       " 'οὕτω',\n",
       " 'οὕτως',\n",
       " 'οὕτωσ',\n",
       " 'οὖν',\n",
       " 'οὗ',\n",
       " 'οὗτος',\n",
       " 'οὗτοσ',\n",
       " 'παρ',\n",
       " 'παρά',\n",
       " 'παρα',\n",
       " 'παρὰ',\n",
       " 'περί',\n",
       " 'περὶ',\n",
       " 'ποια',\n",
       " 'ποιεσ',\n",
       " 'ποιο',\n",
       " 'ποιοι',\n",
       " 'ποιοσ',\n",
       " 'ποιουσ',\n",
       " 'ποιων',\n",
       " 'ποτε',\n",
       " 'που',\n",
       " 'ποῦ',\n",
       " 'προ',\n",
       " 'προσ',\n",
       " 'πρόσ',\n",
       " 'πρὸ',\n",
       " 'πρὸς',\n",
       " 'πως',\n",
       " 'πωσ',\n",
       " 'σε',\n",
       " 'στη',\n",
       " 'στην',\n",
       " 'στο',\n",
       " 'στον',\n",
       " 'σόσ',\n",
       " 'σύ',\n",
       " 'σύν',\n",
       " 'σὸς',\n",
       " 'σὺ',\n",
       " 'σὺν',\n",
       " 'τά',\n",
       " 'τήν',\n",
       " 'τί',\n",
       " 'τίς',\n",
       " 'τίσ',\n",
       " 'τα',\n",
       " 'ταῖς',\n",
       " 'τε',\n",
       " 'την',\n",
       " 'τησ',\n",
       " 'τι',\n",
       " 'τινα',\n",
       " 'τις',\n",
       " 'τισ',\n",
       " 'το',\n",
       " 'τοί',\n",
       " 'τοι',\n",
       " 'τοιοῦτος',\n",
       " 'τοιοῦτοσ',\n",
       " 'τον',\n",
       " 'τοτε',\n",
       " 'του',\n",
       " 'τούσ',\n",
       " 'τοὺς',\n",
       " 'τοῖς',\n",
       " 'τοῦ',\n",
       " 'των',\n",
       " 'τό',\n",
       " 'τόν',\n",
       " 'τότε',\n",
       " 'τὰ',\n",
       " 'τὰς',\n",
       " 'τὴν',\n",
       " 'τὸ',\n",
       " 'τὸν',\n",
       " 'τῆς',\n",
       " 'τῆσ',\n",
       " 'τῇ',\n",
       " 'τῶν',\n",
       " 'τῷ',\n",
       " 'ωσ',\n",
       " \"ἀλλ'\",\n",
       " 'ἀλλά',\n",
       " 'ἀλλὰ',\n",
       " 'ἀλλ’',\n",
       " 'ἀπ',\n",
       " 'ἀπό',\n",
       " 'ἀπὸ',\n",
       " 'ἀφ',\n",
       " 'ἂν',\n",
       " 'ἃ',\n",
       " 'ἄλλος',\n",
       " 'ἄλλοσ',\n",
       " 'ἄν',\n",
       " 'ἄρα',\n",
       " 'ἅμα',\n",
       " 'ἐάν',\n",
       " 'ἐγώ',\n",
       " 'ἐγὼ',\n",
       " 'ἐκ',\n",
       " 'ἐμόσ',\n",
       " 'ἐμὸς',\n",
       " 'ἐν',\n",
       " 'ἐξ',\n",
       " 'ἐπί',\n",
       " 'ἐπεὶ',\n",
       " 'ἐπὶ',\n",
       " 'ἐστι',\n",
       " 'ἐφ',\n",
       " 'ἐὰν',\n",
       " 'ἑαυτοῦ',\n",
       " 'ἔτι',\n",
       " 'ἡ',\n",
       " 'ἢ',\n",
       " 'ἣ',\n",
       " 'ἤ',\n",
       " 'ἥ',\n",
       " 'ἧς',\n",
       " 'ἵνα',\n",
       " 'ὁ',\n",
       " 'ὃ',\n",
       " 'ὃν',\n",
       " 'ὃς',\n",
       " 'ὅ',\n",
       " 'ὅδε',\n",
       " 'ὅθεν',\n",
       " 'ὅπερ',\n",
       " 'ὅς',\n",
       " 'ὅσ',\n",
       " 'ὅστις',\n",
       " 'ὅστισ',\n",
       " 'ὅτε',\n",
       " 'ὅτι',\n",
       " 'ὑμόσ',\n",
       " 'ὑπ',\n",
       " 'ὑπέρ',\n",
       " 'ὑπό',\n",
       " 'ὑπὲρ',\n",
       " 'ὑπὸ',\n",
       " 'ὡς',\n",
       " 'ὡσ',\n",
       " 'ὥς',\n",
       " 'ὥστε',\n",
       " 'ὦ',\n",
       " 'ᾧ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english')) #cording to NLTK english language contains around 179 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO develop the Language Classification or Language Detection using Stop Words with NLTK\n",
    "\n",
    "we loop through the list of stop words in all languages and check how many stop words our text contains for each language.\n",
    "\n",
    "then text is classified to be in the language in which it has the most stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arabic': 0,\n",
       " 'azerbaijani': 0,\n",
       " 'danish': 1,\n",
       " 'dutch': 2,\n",
       " 'english': 0,\n",
       " 'finnish': 0,\n",
       " 'french': 0,\n",
       " 'german': 12,\n",
       " 'greek': 0,\n",
       " 'hungarian': 0,\n",
       " 'indonesian': 0,\n",
       " 'italian': 0,\n",
       " 'kazakh': 0,\n",
       " 'nepali': 0,\n",
       " 'norwegian': 1,\n",
       " 'portuguese': 1,\n",
       " 'romanian': 0,\n",
       " 'russian': 0,\n",
       " 'slovene': 0,\n",
       " 'spanish': 0,\n",
       " 'swedish': 0,\n",
       " 'tajik': 0,\n",
       " 'turkish': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_ratios = {}\n",
    "\n",
    "test_words = [word.lower() for word in test_tokens] # make all tokens to be lower\n",
    "test_words_set = set(test_words)\n",
    "\n",
    "for language in stopwords.fileids():\n",
    "    stopwords_set = set(stopwords.words(language)) # for some language e.g Russian,\n",
    "    # it would be a wise idea to tokenize the stop words by punctuation too.\n",
    "    common_elements = test_words_set.intersection(stopwords_set)\n",
    "    language_ratios[language] = len(common_elements) # language score\n",
    "    \n",
    "language_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated_language = max(language_ratios, key=language_ratios.get)\n",
    "most_rated_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allen',\n",
       " 'auf',\n",
       " 'das',\n",
       " 'der',\n",
       " 'die',\n",
       " 'hat',\n",
       " 'ihren',\n",
       " 'ist',\n",
       " 'jeder',\n",
       " 'und',\n",
       " 'werden',\n",
       " 'zum'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_set.intersection(set(stopwords.words(most_rated_language)))\n",
    "# to see which english stop words were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
